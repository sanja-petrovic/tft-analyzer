{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51dc93-ca4f-4037-81fc-f716b7297c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from loguru import logger\n",
    "from typing import Union\n",
    "from delta import DeltaTable\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    count,\n",
    "    when,\n",
    "    avg,\n",
    "    desc,\n",
    "    rank,\n",
    ")\n",
    "\n",
    "\n",
    "def create_spark() -> SparkSession:\n",
    "    return (\n",
    "        SparkSession.builder.master(\"spark://spark-master:7077\")\n",
    "        .appName(\"tft-analyzer-batch-trait-metrics\")\n",
    "        .config(\"spark.driver.extraJavaOptions\", \"-Duser.timezone=GMT\")\n",
    "        .config(\"spark.executor.extraJavaOptions\", \"-Duser.timezone=GMT\")\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "        .config(\n",
    "            \"spark.jars.packages\",\n",
    "            \"io.delta:delta-core_2.12:2.2.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.apache.spark:spark-avro_2.12:3.3.0\",\n",
    "        )\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\n",
    "            \"spark.delta.logStore.class\",\n",
    "            \"org.apache.spark.sql.delta.storage.HDFSLogStore\",\n",
    "        )\n",
    "        .config(\n",
    "            \"spark.sql.catalog.spark_catalog\",\n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\",\n",
    "        )\n",
    "        .config(\"spark.sql.warehouse.dir\", \"hdfs://namenode:9000/user/hive/warehouse\")\n",
    "        .config(\n",
    "            \"spark.hadoop.javax.jdo.option.ConnectionURL\",\n",
    "            \"jdbc:postgresql://hive-metastore-postgresql/metastore\",\n",
    "        )\n",
    "        .config(\n",
    "            \"spark.hadoop.javax.jdo.option.ConnectionDriverName\",\n",
    "            \"org.postgresql.Driver\",\n",
    "        )\n",
    "        .config(\"spark.hadoop.javax.jdo.option.ConnectionUserName\", \"hive\")\n",
    "        .config(\"spark.hadoop.javax.jdo.option.ConnectionPassword\", \"hive\")\n",
    "        .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://hive-metastore:9083\")\n",
    "        .config(\"spark.pyspark.python\", \"python3\")\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "\n",
    "def read_delta(table: str, spark) -> DataFrame:\n",
    "    logger.info(f'Started reading from \"{table}\"...')\n",
    "    df: DataFrame = spark.read.format(\"delta\").table(table)\n",
    "    logger.info(f'Finished reading from \"{table}\".')\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_delta(\n",
    "    df,\n",
    "    table: str,\n",
    "    mode: str = \"append\",\n",
    "    partition_by: Union[str, None] = None,\n",
    ") -> None:\n",
    "    logger.info(f'Started writing to Delta table \"{table}\"...')\n",
    "    df.write.format(\"delta\").option(\"mergeSchema\", \"true\").saveAsTable(\n",
    "        table, partitionBy=partition_by, mode=mode\n",
    "    )\n",
    "    logger.info(f'Finished writing to Delta table \"{table}\".')\n",
    "\n",
    "\n",
    "def upsert(\n",
    "    new_alias: str,\n",
    "    existing_alias: str,\n",
    "    new_df: DataFrame,\n",
    "    existing_table,\n",
    "    condition: str,\n",
    "):\n",
    "    logger.info(f'Started upserting to Delta table \"{existing_alias}\"...')\n",
    "    existing_table.alias(existing_alias).merge(\n",
    "        new_df.alias(new_alias),\n",
    "        condition,\n",
    "    ).whenNotMatchedInsertAll().whenMatchedUpdateAll().execute()\n",
    "    logger.info(f'Finished upserting to Delta table \"{existing_alias}\".')\n",
    "\n",
    "\n",
    "def table_exists(spark, table, db) -> None:\n",
    "    result = spark.sql(f\"SHOW TABLES IN {db}\")\n",
    "    return bool(result.filter(col(\"tableName\").contains(table)).collect())\n",
    "\n",
    "\n",
    "def write_or_upsert(\n",
    "    spark,\n",
    "    df: DataFrame,\n",
    "    table_name: str,\n",
    "    condition: str,\n",
    "    partition_by: Union[str, None] = None,\n",
    "):\n",
    "    splitted = table_name.split(\".\")\n",
    "    if table_exists(spark, splitted[1], splitted[0]):\n",
    "        try:\n",
    "            existing_silver = DeltaTable.convertToDelta(spark, table_name)\n",
    "            upsert(\n",
    "                \"new_table\",\n",
    "                table_name,\n",
    "                df,\n",
    "                existing_silver,\n",
    "                condition,\n",
    "            )\n",
    "        except Exception:\n",
    "            write_delta(df, table_name, partition_by=partition_by)\n",
    "    else:\n",
    "        write_delta(df, table_name, partition_by=partition_by)\n",
    "\n",
    "\n",
    "def calculate_compositions(df):\n",
    "    \"\"\"\n",
    "    Compositions are an important concept in TFT.\n",
    "    They can be defined as a combination of two traits.\n",
    "    Usually, players are interested in knowing the best performing compositions that will help them climb ranks.\n",
    "    Questions these metrics aim to answer:\n",
    "    1. How strong is each composition?\n",
    "    2. How popular are these compositions? (pick rate)\n",
    "    3. Are players gaining rank by playing this composition (top 1 rate)?.\n",
    "    3. Are players winning by playing this composition (top 1 rate)?.\n",
    "    4. What is the average placement of these compositions?\n",
    "    5. What are the 25 best performing compositions?\n",
    "    \"\"\"\n",
    "    trait_combinations = (\n",
    "        df.alias(\"a\")\n",
    "        .join(\n",
    "            df.alias(\"b\"),\n",
    "            (col(\"a.match_id\") == col(\"b.match_id\"))\n",
    "            & (col(\"a.puuid\") == col(\"b.puuid\"))\n",
    "            & (col(\"a.placement\") == col(\"b.placement\"))\n",
    "            & (col(\"a.trait_id\") != col(\"b.trait_id\"))\n",
    "            & (col(\"a.trait_tier\") < col(\"b.trait_tier\")),\n",
    "            \"inner\",\n",
    "        )\n",
    "        .select(\n",
    "            col(\"a.trait_id\").alias(\"trait1\"),\n",
    "            col(\"b.trait_id\").alias(\"trait2\"),\n",
    "            col(\"a.trait_tier\").alias(\"trait1_tier\"),\n",
    "            col(\"b.trait_tier\").alias(\"trait2_tier\"),\n",
    "            col(\"a.trait_unit_count\").alias(\"trait1_unit_count\"),\n",
    "            col(\"b.trait_unit_count\").alias(\"trait2_unit_count\"),\n",
    "            col(\"a.trait_tier_max\").alias(\"trait1_tier_max\"),\n",
    "            col(\"b.trait_tier_max\").alias(\"trait2_tier_max\"),\n",
    "            \"a.placement\",\n",
    "        )\n",
    "        .filter(col(\"trait1_tier_max\") > 1)\n",
    "        .filter(col(\"trait2_tier_max\") > 1)\n",
    "    )\n",
    "\n",
    "    trait_combinations_metrics = trait_combinations.groupBy(\n",
    "        \"trait1\",\n",
    "        \"trait2\",\n",
    "        \"trait1_tier\",\n",
    "        \"trait2_tier\",\n",
    "        \"trait1_tier_max\",\n",
    "        \"trait2_tier_max\",\n",
    "    ).agg(\n",
    "        avg(col(\"placement\")).alias(\"avg_placement\"),\n",
    "        count(\"*\").alias(\"total_matches\"),\n",
    "        count(when(col(\"placement\") <= 4, True)).alias(\"top_4_matches\"),\n",
    "        count(when(col(\"placement\") == 1, True)).alias(\"top_1_matches\"),\n",
    "        (col(\"trait1_tier\") / col(\"trait1_tier_max\")).alias(\"trait1_strength\"),\n",
    "        (col(\"trait2_tier\") / col(\"trait2_tier_max\")).alias(\"trait2_strength\"),\n",
    "    )\n",
    "\n",
    "    strength_combinations = (\n",
    "        trait_combinations_metrics.withColumn(\n",
    "            \"pick_rate\",\n",
    "            (col(\"total_matches\") / df.select(\"match_id\").distinct().count()),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"top_4_rate\",\n",
    "            (col(\"top_4_matches\") / col(\"total_matches\") * 100).alias(\"top_4_rate\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"top_1_rate\",\n",
    "            (col(\"top_1_matches\") / col(\"total_matches\") * 100).alias(\"top_1_rate\"),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"strength\",\n",
    "            (8 / col(\"avg_placement\"))\n",
    "            * (col(\"trait1_strength\") * col(\"trait2_strength\"))\n",
    "            * col(\"pick_rate\")\n",
    "            * col(\"top_4_rate\")\n",
    "            * col(\"top_1_rate\"),\n",
    "        )\n",
    "    )\n",
    "    average_strength = strength_combinations.groupBy(\n",
    "        \"trait1\",\n",
    "        \"trait2\",\n",
    "    ).agg(\n",
    "        avg(col(\"strength\")).alias(\"strength\"),\n",
    "        avg(col(\"avg_placement\")).alias(\"avg_placement\"),\n",
    "        avg(col(\"pick_rate\")).alias(\"pick_rate\"),\n",
    "        avg(col(\"top_4_rate\")).alias(\"top_4_rate\"),\n",
    "        avg(col(\"top_1_rate\")).alias(\"top_1_rate\"),\n",
    "    )\n",
    "    ranked_combinations = average_strength.withColumn(\n",
    "        \"rank\", rank().over(Window.orderBy(desc(\"strength\")))\n",
    "    )\n",
    "    return ranked_combinations.filter(\"rank <= 25\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = create_spark()\n",
    "    match_traits_df = read_delta(\"silver.match_traits\", spark)\n",
    "    composition_df = calculate_compositions(match_traits_df)\n",
    "    composition_df.show(25, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6b889-f300-4c54-b8c0-565605923a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2e4de-6679-485b-8cfa-0e6ef3523314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
